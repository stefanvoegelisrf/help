# Large language models

- [Large language models](#large-language-models)
  - [Running large language models locally](#running-large-language-models-locally)
    - [Running locally with ollama.ai](#running-locally-with-ollamaai)
    - [Running locally with GPT4ALL](#running-locally-with-gpt4all)
    - [Running Stable Diffusion locally](#running-stable-diffusion-locally)


## Prompting

TODO:

## Models/Tools

- [GPT4](https://openai.com/gpt-4)
- [DALL-E 2](https://openai.com/dall-e-2)
- [Stable Diffusion](https://stability.ai/stable-diffusion)
- [Claude](https://claude.ai/)
  - TODO: check out https://www.anthropic.com/index/introducing-claude

## Running large language models locally

### Running locally with [ollama.ai](https://ollama.ai/)

With ollama large language models can be easily downloaded and run in the terminal.

Install the tool and then e.g. run llama2 with `ollama run llama2`.

### Running locally with [GPT4ALL](https://gpt4all.io/index.html)

GPT4ALL is a tool to run large language models locally with a chat interface.

### Running Stable Diffusion locally

See: [datacamp.com - How to run Stable Diffusion](https://www.datacamp.com/tutorial/how-to-run-stable-diffusion)